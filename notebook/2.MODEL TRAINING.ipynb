{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc,precision_score,recall_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,StackingClassifier , BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1006 entries, 0 to 1005\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Gender          1006 non-null   int64  \n",
      " 1   Experience      1006 non-null   float64\n",
      " 2   Niveau          1006 non-null   float64\n",
      " 3   Weighted_Score  1006 non-null   float64\n",
      " 4   Output          1006 non-null   float64\n",
      " 5   Domain          1006 non-null   int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 47.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data/clean_data.csv')\n",
    "print(data.info())\n",
    "df=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X:\n",
      "   Gender  Experience  Niveau  Domain\n",
      "0       1        0.24    0.42       6\n",
      "1       0        0.03    0.25      10\n",
      "2       1        0.10    0.17       9\n",
      "3       1        0.24    0.42       2\n",
      "4       1        0.07    0.42       3\n",
      "\n",
      "y:\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Output, dtype: float64\n",
      "\n",
      "X shape : (1006, 4)\n",
      "y shape : (1006,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Output', 'Weighted_Score'], axis=1)\n",
    "y = df['Output']\n",
    "\n",
    "print(\"\\nX:\")\n",
    "print(X[:5])\n",
    "print(\"\\ny:\")\n",
    "print(y[:5])\n",
    "print('\\nX shape :',X.shape)\n",
    "print('y shape :',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Split dataset to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Initialize empty lists of metrics and models' list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Linear Discriminant Analysis(LDA)': LinearDiscriminantAnalysis(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'NB': GaussianNB(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "model_list = []\n",
    "model_names = []\n",
    "accuracy_score_train_values = []\n",
    "accuracy_score_test_values = []\n",
    "auc_test_values = []\n",
    "roc_auc_test_values = []\n",
    "f1_score_test_values = []\n",
    "f1_score_test_values_mean = []\n",
    "precision_test_values = []\n",
    "precision_test_values_mean = []\n",
    "recall_test_values = []\n",
    "recall_test_values_mean = []\n",
    "confusion_matrix_test_values = []\n",
    "gini_coefficient_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Iterate over the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 0.9366\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.8812\n",
      "Auc: 0.8788\n",
      "Roc: 0.8788\n",
      "f1_score: [0.89565217 0.86206897]\n",
      "f1_score mean: 0.8789\n",
      "precision_score: [0.81102362 1.        ]\n",
      "precision_score mean : 0.9055\n",
      "recall_score: [1.         0.75757576]\n",
      "recall_score mean : 0.8788\n",
      "Gini Coefficient: 0.7576\n",
      "\n",
      "confusion_matrix: [[103   0]\n",
      " [ 24  75]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 0.89\n",
      "The average test accuracy is 0.87\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 0.92\n",
      "The average test accuracy is 0.93\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 0.94\n",
      "The average test accuracy is 0.94\n",
      "--------------------------------------------------\n",
      "Linear Discriminant Analysis(LDA)\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 0.9378\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.8713\n",
      "Auc: 0.8687\n",
      "Roc: 0.8687\n",
      "f1_score: [0.88793103 0.84883721]\n",
      "f1_score mean: 0.8684\n",
      "precision_score: [0.79844961 1.        ]\n",
      "precision_score mean : 0.8992\n",
      "recall_score: [1.         0.73737374]\n",
      "recall_score mean : 0.8687\n",
      "Gini Coefficient: 0.7374\n",
      "\n",
      "confusion_matrix: [[103   0]\n",
      " [ 26  73]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 0.93\n",
      "The average test accuracy is 0.93\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 0.93\n",
      "The average test accuracy is 0.94\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 0.94\n",
      "The average test accuracy is 0.94\n",
      "--------------------------------------------------\n",
      "KNN\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 0.9614\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.8960\n",
      "Auc: 0.8945\n",
      "Roc: 0.8945\n",
      "f1_score: [0.90497738 0.8852459 ]\n",
      "f1_score mean: 0.8951\n",
      "precision_score: [0.84745763 0.96428571]\n",
      "precision_score mean : 0.9059\n",
      "recall_score: [0.97087379 0.81818182]\n",
      "recall_score mean : 0.8945\n",
      "Gini Coefficient: 0.7891\n",
      "\n",
      "confusion_matrix: [[100   3]\n",
      " [ 18  81]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 0.92\n",
      "The average test accuracy is 0.89\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 0.95\n",
      "The average test accuracy is 0.91\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 0.96\n",
      "The average test accuracy is 0.94\n",
      "--------------------------------------------------\n",
      "NB\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 0.9216\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.8465\n",
      "Auc: 0.8444\n",
      "Roc: 0.8444\n",
      "f1_score: [0.86343612 0.82485876]\n",
      "f1_score mean: 0.8441\n",
      "precision_score: [0.79032258 0.93589744]\n",
      "precision_score mean : 0.8631\n",
      "recall_score: [0.95145631 0.73737374]\n",
      "recall_score mean : 0.8444\n",
      "Gini Coefficient: 0.6888\n",
      "\n",
      "confusion_matrix: [[98  5]\n",
      " [26 73]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 0.92\n",
      "The average test accuracy is 0.89\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 0.91\n",
      "The average test accuracy is 0.90\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 0.90\n",
      "The average test accuracy is 0.90\n",
      "--------------------------------------------------\n",
      "SVM\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 0.7226\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 0.6386\n",
      "Auc: 0.6356\n",
      "Roc: 0.6356\n",
      "f1_score: [0.6893617  0.56804734]\n",
      "f1_score mean: 0.6287\n",
      "precision_score: [0.61363636 0.68571429]\n",
      "precision_score mean : 0.6497\n",
      "recall_score: [0.78640777 0.48484848]\n",
      "recall_score mean : 0.6356\n",
      "Gini Coefficient: 0.2713\n",
      "\n",
      "confusion_matrix: [[81 22]\n",
      " [51 48]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 0.63\n",
      "The average test accuracy is 0.64\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 0.66\n",
      "The average test accuracy is 0.67\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 0.71\n",
      "The average test accuracy is 0.71\n",
      "--------------------------------------------------\n",
      "Decision Tree\n",
      "\n",
      " *** Training Performance:\n",
      "Accuracy: 1.0000\n",
      "\n",
      " *** Testing Performance:\n",
      "Accuracy: 1.0000\n",
      "Auc: 1.0000\n",
      "Roc: 1.0000\n",
      "f1_score: [1. 1.]\n",
      "f1_score mean: 1.0000\n",
      "precision_score: [1. 1.]\n",
      "precision_score mean : 1.0000\n",
      "recall_score: [1. 1.]\n",
      "recall_score mean : 1.0000\n",
      "Gini Coefficient: 1.0000\n",
      "\n",
      "confusion_matrix: [[103   0]\n",
      " [  0  99]]\n",
      "--------------------\n",
      "\n",
      "\n",
      "241 samples were used to train the model\n",
      "The average train accuracy is 1.00\n",
      "The average test accuracy is 0.99\n",
      "\n",
      "\n",
      "482 samples were used to train the model\n",
      "The average train accuracy is 1.00\n",
      "The average test accuracy is 0.99\n",
      "\n",
      "\n",
      "723 samples were used to train the model\n",
      "The average train accuracy is 1.00\n",
      "The average test accuracy is 1.00\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict \n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate performance on training set\n",
    "    accuracy_score_train=accuracy_score(y_train, y_train_pred, normalize=True)\n",
    "\n",
    "    # Evaluate performance on testing  set\n",
    "    accuracy_score_test=accuracy_score(y_test, y_pred, normalize=True)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    auc_test=metrics.auc(fpr, tpr)\n",
    "    \n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    confusion_matrix_test=confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    f1_score_test=f1_score(y_test, y_pred, average=None)\n",
    "    \n",
    "    gini_coefficient = 2 * roc_auc_test - 1\n",
    "    \n",
    "    precision_test = precision_score(y_test, y_pred, average=None)\n",
    "\n",
    "    recall_test = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "    # Add results to their corresponding arrays\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    accuracy_score_train_values.append(accuracy_score_train)\n",
    "    accuracy_score_test_values.append(accuracy_score_test)\n",
    "    auc_test_values.append(auc_test)\n",
    "    roc_auc_test_values.append(roc_auc_test)\n",
    "    f1_score_test_values.append(f1_score_test)\n",
    "    f1_score_test_values_mean.append(f\"{f1_score_test.mean():.4f}\")\n",
    "    confusion_matrix_test_values.append(confusion_matrix_test)\n",
    "    gini_coefficient_values.append(gini_coefficient)\n",
    "    precision_test_values.append(precision_test)\n",
    "    precision_test_values_mean.append(f\"{precision_test.mean():.4f}\")\n",
    "    recall_test_values.append(recall_test)\n",
    "    recall_test_values_mean.append(f\"{recall_test.mean():.4f}\")\n",
    "    \n",
    "    # Display the results\n",
    "    # print(f'Model: {name}')\n",
    "    print(\"\\n *** Training Performance:\")\n",
    "    print(f\"Accuracy: {accuracy_score_train:.4f}\")\n",
    "    \n",
    "    print(\"\\n *** Testing Performance:\")\n",
    "    print(f'Accuracy: {accuracy_score_test:.4f}')\n",
    "    print(f'Auc: {auc_test:.4f}')\n",
    "    print(f'Roc: {roc_auc_test:.4f}')\n",
    "    print(f'f1_score: {f1_score_test}')\n",
    "    print(f'f1_score mean: {f1_score_test.mean():.4f}')\n",
    "    print(f'precision_score: {precision_test}')\n",
    "    print(f'precision_score mean : {precision_test.mean():.4f}')\n",
    "    print(f'recall_score: {recall_test}')\n",
    "    print(f'recall_score mean : {recall_test.mean():.4f}')\n",
    "    print(f'Gini Coefficient: {gini_coefficient:.4f}')\n",
    "    print(f'\\nconfusion_matrix: {confusion_matrix_test}')\n",
    "    print('-' * 20)\n",
    "    train_size_abs, train_scores, test_scores = learning_curve(\n",
    "        model, X, y, train_sizes=[0.3, 0.6, 0.9]\n",
    "    )\n",
    "    for train_size, cv_train_scores, cv_test_scores in zip(\n",
    "        train_size_abs, train_scores, test_scores\n",
    "    ):\n",
    "        print('\\n')\n",
    "        print(f\"{train_size} samples were used to train the model\")\n",
    "        print(f\"The average train accuracy is {cv_train_scores.mean():.2f}\")\n",
    "        print(f\"The average test accuracy is {cv_test_scores.mean():.2f}\")\n",
    "        \n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>ROC</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Gini coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.961443</td>\n",
       "      <td>0.896040</td>\n",
       "      <td>0.894528</td>\n",
       "      <td>0.894528</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.789056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.936567</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Discriminant Analysis(LDA)</td>\n",
       "      <td>0.937811</td>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.737374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.921642</td>\n",
       "      <td>0.846535</td>\n",
       "      <td>0.844415</td>\n",
       "      <td>0.844415</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.688830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.722637</td>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.635628</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.6356</td>\n",
       "      <td>0.271256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model Name  Train Accuracy  Test Accuracy       AUC  \\\n",
       "5                      Decision Tree        1.000000       1.000000  1.000000   \n",
       "2                                KNN        0.961443       0.896040  0.894528   \n",
       "0                Logistic Regression        0.936567       0.881188  0.878788   \n",
       "1  Linear Discriminant Analysis(LDA)        0.937811       0.871287  0.868687   \n",
       "3                                 NB        0.921642       0.846535  0.844415   \n",
       "4                                SVM        0.722637       0.638614  0.635628   \n",
       "\n",
       "        ROC F1 score Precision  Recall  Gini coefficient  \n",
       "5  1.000000   1.0000    1.0000  1.0000          1.000000  \n",
       "2  0.894528   0.8951    0.9059  0.8945          0.789056  \n",
       "0  0.878788   0.8789    0.9055  0.8788          0.757576  \n",
       "1  0.868687   0.8684    0.8992  0.8687          0.737374  \n",
       "3  0.844415   0.8441    0.8631  0.8444          0.688830  \n",
       "4  0.635628   0.6287    0.6497  0.6356          0.271256  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(\n",
    "    model_list, accuracy_score_train_values,accuracy_score_test_values,\n",
    "    auc_test_values,roc_auc_test_values,f1_score_test_values_mean,precision_test_values_mean,\n",
    "    recall_test_values_mean,gini_coefficient_values)), columns=['Model Name','Train Accuracy', 'Test Accuracy','AUC','ROC','F1 score','Precision','Recall','Gini coefficient']).sort_values(by=[\"Test Accuracy\"],ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
